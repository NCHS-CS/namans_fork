{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping information on books\n",
    "\n",
    "You will use BeautifulSoup to scrape a webpage and extract a list of product titles from an e-commerce page of books.\n",
    "\n",
    "First run the code below to see an example of getting some book titles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Titles:\n",
      "A Light in the Attic\n",
      "Tipping the Velvet\n",
      "Soumission\n",
      "Sharp Objects\n",
      "Sapiens: A Brief History of Humankind\n",
      "The Requiem Red\n",
      "The Dirty Little Secrets of Getting Your Dream Job\n",
      "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\n",
      "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\n",
      "The Black Maria\n",
      "Starving Hearts (Triangular Trade Trilogy, #1)\n",
      "Shakespeare's Sonnets\n",
      "Set Me Free\n",
      "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\n",
      "Rip it Up and Start Again\n",
      "Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\n",
      "Olio\n",
      "Mesaerion: The Best Science Fiction Stories 1800-1849\n",
      "Libertarianism for Beginners\n",
      "It's Only the Himalayas\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of an e-commerce or book listing page (https didn't work in class)\n",
    "url = \"http://books.toscrape.com/\"  # Example website for scraping practice\n",
    "\n",
    "# Send a request to the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the webpage content\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all elements with the atttribute \"title\"\n",
    "titles = soup.select('[title]')\n",
    "\n",
    "# Extract text from each title\n",
    "book_titles = [title.get(\"title\") for title in titles]\n",
    "\n",
    "# Display the results\n",
    "print(\"Book Titles:\")\n",
    "for title in book_titles:\n",
    "    print(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we really need to extract the title and price of each book from the webpage.\n",
    "To do this you will need to get the parent of each book (the code has been started for you below).\n",
    "\n",
    "Use the beautifulsoup documentation [here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) to help get this information from the container.\n",
    "\n",
    "`Note that using the debugger with breakpoints here and looking at the items returned may help.`\n",
    "\n",
    "The hints are included in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = soup.find_all(\"article\")  # Find all book containers instead\n",
    "\n",
    "# Extract title and price for each book\n",
    "book_data = []\n",
    "\n",
    "for book in books:\n",
    "    # Extract title (inside <h3> tag under <a> title attribute)\n",
    "    title = \"\"\n",
    "\n",
    "    # Extract price (inside <p> tag with class 'price_color'), hint: class_ helps.\n",
    "    price = \"\" \n",
    "\n",
    "    # Store as tuple\n",
    "    book_data.append((title, price))\n",
    "\n",
    "# Display the extracted data\n",
    "print(\"Books with Prices:\")\n",
    "for title, price in book_data:\n",
    "    print(f\"{title} - {price}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look something like this (with probably different books):\n",
    "\n",
    "```\n",
    "Books with Prices:\n",
    "A Light in the Attic - Â£51.77\n",
    "Tipping the Velvet - Â£53.74\n",
    "Soumission - Â£50.10\n",
    "Sharp Objects - Â£47.82\n",
    "Sapiens: A Brief History of Humankind - Â£54.23\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you have scraped your web data. Raise your paddlepop and get signed off.\n",
    "\n",
    "The next step is to add to add saving the data out to a CSV file!\n",
    "\n",
    "## Step 2: Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Now we'll add scrpaing book_data (Using  the previous solution here and extend it\n",
    "# for rating and availability\n",
    "\n",
    "def scrape_books(page_url):\n",
    "    \"\"\"Scrapes book details (title, price, rating, availability) from a single page.\"\"\"\n",
    "    \n",
    "    response = requests.get(page_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    book_data = []\n",
    "\n",
    "    for book in books:\n",
    "        title = book.h3.a[\"title\"]\n",
    "        price = book.find(\"p\", class_=\"price_color\").get_text(strip=True)       \n",
    "        # ************************************\n",
    "        # TODO: Add rating and availability \n",
    "        # ************************************\n",
    "        rating = \"\"\n",
    "        availability = \"\"\n",
    "\n",
    "        book_data.append([title, price, rating, availability])\n",
    "\n",
    "    return book_data\n",
    "\n",
    "# Base URL\n",
    "base_url = \"http://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "# Scrape data from page 1 and page 2\n",
    "all_books = []\n",
    "for page in range(1, 3):  # Loop through two pages\n",
    "    url = base_url.format(page)\n",
    "    print(f\"Scraping {url}...\")\n",
    "    all_books.extend(scrape_books(url))\n",
    "\n",
    "# Save to CSV\n",
    "csv_filename = \"books_data.csv\"\n",
    "\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    # ************************************\n",
    "    # TODO: Add the output data to write here for headers and rows.\n",
    "    writer.writerow([\"TODO\"])\n",
    "    # ************************************\n",
    "\n",
    "\n",
    "print(f\"Data successfully saved to {csv_filename}\")\n",
    "\n",
    "# Open and print CSV content\n",
    "with open(csv_filename, \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        print(line.strip())  # Print each line, removing extra spaces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
